{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3962a900-4a4c-4360-8f41-a9b0de4d6d18",
   "metadata": {},
   "source": [
    "# Formatting Anki Flashcards\n",
    "\n",
    "In this notebook, we are exploring the best way to prompt an LLM to improve the formatting of Anki flashcards. \n",
    "\n",
    "Approaches we are including:\n",
    "1. Simple prompt\n",
    "2. Simple prompt + Chain of Thought\n",
    "3. Two-step process (critique â†’ refine)\n",
    "4. Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b40c65b-b584-47c7-9094-24187a434858",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471e4473-274b-491a-ae26-fa61d07b715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from anki.collection import Collection\n",
    "\n",
    "from addon.application.use_cases.note_counter import is_note_marked_for_review\n",
    "from addon.infrastructure.configuration.settings import AddonConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a631ea3e-b3b2-471d-8395-30c898b07a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes: 3362\n",
      "Number of cards: 3498\n"
     ]
    }
   ],
   "source": [
    "# Open an existing collection\n",
    "col = Collection(\"/home/gianluca/.local/share/Anki2/User 1/collection.anki2\")\n",
    "\n",
    "# Do something with the collection\n",
    "print(f\"Number of notes: {col.note_count()}\")\n",
    "print(f\"Number of cards: {col.card_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90859fd3-c78b-44f3-b03c-d4d565446970",
   "metadata": {},
   "source": [
    "### Connect to Inference Server\n",
    "\n",
    "For this notebook, we are going to use `Qwen3-14B-Q8_0.gguf` (from `unsloth`). This is a larger and more modern LLM compared to `Llama-3.1-8b-instruct`, which should lead to better results. We are also going to use the Chat Completion API, which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed266c25-a5ae-4cff-b374-87fc37cf7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Mode(Enum):\n",
    "    COMPLETION = \"v1/completions\"\n",
    "    CHAT_COMPLETION = \"v1/chat/completions\"\n",
    "    # response API not supported in vLLM yet\n",
    "\n",
    "def answer(prompt, model_name: str = \"./Qwen3-14B-Q8_0.gguf\", mode: Mode = Mode.CHAT_COMPLETION):\n",
    "    config = AddonConfig.create_nullable()\n",
    "\n",
    "    url = f\"http://iamgianluca.ddns.net:8080/{mode.value}\"  # chat completion API\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [  # TODO: parametrize. Should be \"text\" for Completion API\n",
    "            # {'role': 'system', 'content': 'Answer directly without any thinking tags or explanations. /no_think'},\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 4_000,  # config.max_tokens,\n",
    "        \"temperature\": config.temperature,\n",
    "        \"top_p\": config.top_p,\n",
    "        \"min_p\": config.min_p,\n",
    "        \"top_k\": config.top_k,\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    if mode == Mode.CHAT_COMPLETION:\n",
    "        print(response)\n",
    "        reasoning_content = response.json()[\"choices\"][0][\"message\"][\n",
    "            \"reasoning_content\"\n",
    "        ]\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]  # chat completion API\n",
    "        print(f\"Content: {content.replace('<think>\\n\\n</think>\\n\\n', '')}\")\n",
    "        print(f\"Reasoning: {reasoning_content}\")\n",
    "        return (content, reasoning_content)\n",
    "        \n",
    "    if mode == Mode.COMPLETION:\n",
    "        print(response)\n",
    "        content = response.json()[\"choices\"][0][\"text\"]\n",
    "        print(f\"Content: {content}\")\n",
    "        return (content, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efc5e84-5fb7-4963-9e13-3626e4b3c625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Content: ciao\n",
      "Reasoning: None\n"
     ]
    }
   ],
   "source": [
    "content, reasoning_content = answer(\n",
    "    \"Respond only with one word, lowercase, without punctuation. What is the Italian word for 'hello'? /no_think\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d3f1b-7b16-4c22-a8ba-c78109a2fa04",
   "metadata": {},
   "source": [
    "We have everything we need now to tell the LLM to make some changes to our Anki flashcards.\n",
    "\n",
    "Let's pull a few note currently marked for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4449c78a-c525-43b3-96f4-cf665617105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_id = col.decks.current()[\"id\"]\n",
    "query = f\"did:{deck_id}\"\n",
    "note_ids = col.find_notes(query)\n",
    "\n",
    "NUM_NOTES_NEEDED = 10\n",
    "\n",
    "flagged_notes = []\n",
    "for note_id in note_ids:\n",
    "    if is_note_marked_for_review(col, note_id):\n",
    "        note = col.get_note(note_id)\n",
    "        flagged_notes.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cad38b4-78b1-4790-8e4b-b2a77e763c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flagged notes: 268\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of flagged notes: {len(flagged_notes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c735cfe6-db80-45d6-89d3-72acf9cbaf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01900f2a-bea3-45ec-b277-8c8166e607f1",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "- [ ] Check if we have a class that we can use to read the collection from the hard disk and convert it to `AddonNote` instead of `Note`. In that way we can operate with domain objects instead of external dependencies. The same class should be used to convert the `AddonNote` back to `Note` (so maybe we should keep track of the `note_id`\n",
    "- [ ] Once we have that class, we should update the rest of the codebase accordingly (e.g., note formatter, note counter, etc.)\n",
    "- [ ] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c8e77-6198-4a26-b303-65546c7249cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
